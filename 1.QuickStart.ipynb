{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![SparkPdf](https://stabrise.com/media/filer_public_thumbnails/filer_public/de/31/de3156f0-386d-4b3b-ac7e-8856a38f7c1e/sparkpdflogo.png__808x214_subsampling-2.webp)\n",
    "\n",
    "<p align=\"center\">\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/StabRise/spark-pdf-tutorials/blob/master/1.QuickStart.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "    <a href=\"https://pypi.org/project/pyspark-pdf/\" alt=\"Package on PyPI\"><img src=\"https://img.shields.io/pypi/v/pyspark-pdf.svg\" /></a>    \n",
    "    <a href=\"https://github.com/stabrise/spark-pdf/blob/main/LICENSE\"><img alt=\"GitHub\" src=\"https://img.shields.io/github/license/stabrise/spark-pdf.svg?color=blue\"></a>\n",
    "    <a href=\"https://stabrise.com\"><img alt=\"StabRise\" src=\"https://img.shields.io/badge/powered%20by-StabRise-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\"></a>\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89ed4125ac19d826"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quick Star with Spark-Pdf\n",
    "\n",
    "Spark-Pdf is open-source library for deal with documents built on top of the Apace Spark.\n",
    "\n",
    "Supported formats:\n",
    "- Pdf files (scanned and searchable)\n",
    "- Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71ba8d6b59dfc550"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cf40d6ddb0bfa61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "[[ ! \"${COLAB_RELEASE_TAG}\" ]] && exit\n",
    "sudo apt install tesseract-ocr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96cff45108a575ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyspark-pdf[ml]==0.1.0rc9"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fe85b8534a5f48e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start Spark Session with Spark Pdf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca89bc40931b5a94"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 17:23:53 WARN Utils: Your hostname, nmelnik-1-0 resolves to a loopback address: 127.0.1.1; using 192.168.0.105 instead (on interface wlo1)\n",
      "24/11/11 17:23:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/11 17:23:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "24/11/11 17:23:54 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x7370f5703a50>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://192.168.0.105:4047\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>SparkPdf</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparkpdf import *\n",
    "\n",
    "spark = SparkPdfSession()\n",
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T16:23:55.268999841Z",
     "start_time": "2024-11-11T16:23:52.527133689Z"
    }
   },
   "id": "e6f825624c8153ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Pdf file to the Spark DataFrame and show it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cc9bd5f79f096e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pdf_example = files('resources/pdfs/SparkPdf.pdf')\n",
    "\n",
    "df = spark.read.format(\"binaryFile\") \\\n",
    "    .load(pdf_example)\n",
    "\n",
    "df.show_pdf()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "801feff3ef18aa2d"
  },
  {
   "cell_type": "markdown",
   "id": "7b708a7685a1dc95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define pipeline for extract text from the PDF and call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377c29eb0c220b83",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T07:48:37.467592305Z",
     "start_time": "2024-11-05T07:48:35.649861591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+----+--------------------+\n",
      "|                path|    modificationTime|length|page|                text|\n",
      "+--------------------+--------------------+------+----+--------------------+\n",
      "|file:/home/nmelni...|2024-11-03 14:26:...| 84947|   0|{file:/home/nmeln...|\n",
      "+--------------------+--------------------+------+----+--------------------+\n"
     ]
    }
   ],
   "source": [
    "pipeline = PipelineModel(stages=[\n",
    "    PdfDataToImage(),\n",
    "    TesseractOcr(keepFormatting=True, psm=PSM.SPARSE_TEXT)\n",
    "])\n",
    "\n",
    "result = pipeline.transform(df).cache()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f734da96d957a6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show schema of result DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279675145ef3d683",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T07:48:37.467730974Z",
     "start_time": "2024-11-05T07:48:37.464527017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- page: integer (nullable = true)\n",
      " |-- text: struct (nullable = true)\n",
      " |    |-- path: string (nullable = false)\n",
      " |    |-- text: string (nullable = false)\n",
      " |    |-- type: string (nullable = false)\n",
      " |    |-- bboxes: array (nullable = false)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = false)\n",
      " |    |    |    |-- score: double (nullable = false)\n",
      " |    |    |    |-- x: integer (nullable = false)\n",
      " |    |    |    |-- y: integer (nullable = false)\n",
      " |    |    |    |-- width: integer (nullable = false)\n",
      " |    |    |    |-- height: integer (nullable = false)\n",
      " |    |-- exception: string (nullable = false)\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab607d34859d539",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show coordinates for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf7cc82fce38a7d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T07:48:37.620903101Z",
     "start_time": "2024-11-05T07:48:37.467653084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----+----+-----+------+\n",
      "|            text|             score|   x|   y|width|height|\n",
      "+----------------+------------------+----+----+-----+------+\n",
      "|           Spark|0.9651048299999999| 852| 448|  794|   263|\n",
      "|             Pdf|0.9118479899999999|1745| 453|  442|   210|\n",
      "|           Spark|0.9682291399999999| 304|1134|  272|    93|\n",
      "|             Pdf|        0.96166916| 613|1134|  157|    74|\n",
      "|       Spark-Pdf|        0.86371033| 302|1333|  194|    41|\n",
      "|             for|0.9669332900000001| 718|1333|   52|    33|\n",
      "|           Spark|0.9690411400000001|1510|1333|  112|    41|\n",
      "|              is|        0.94951027| 509|1334|   28|    32|\n",
      "|         library|        0.96251343| 590|1334|  115|    40|\n",
      "|      processing|        0.96082161| 784|1334|  206|    40|\n",
      "|       documents|0.9621209000000001|1006|1334|  211|    32|\n",
      "|           using|        0.96825851|1234|1334|   99|    40|\n",
      "|          Apache|        0.96818832|1348|1334|  147|    40|\n",
      "|               a|0.9634259799999999| 552|1342|   21|    24|\n",
      "|       following|0.9613777899999999| 582|1441|  168|    41|\n",
      "|       features:|         0.9653299| 765|1441|  166|    33|\n",
      "|              It|         0.9554335| 304|1442|   20|    31|\n",
      "|        includes|        0.96590355| 339|1442|  156|    32|\n",
      "|             the|        0.96355103| 510|1442|   58|    32|\n",
      "|documents/Images|        0.91310028| 660|1549|  367|    41|\n",
      "+----------------+------------------+----+----+-----+------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import  explode\n",
    "result.select(explode(\"text.bboxes\").alias(\"bboxes\")).select(\"bboxes.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a3ebbb3295a15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show recognized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e95b3dee45dd5d0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T07:48:37.691392156Z",
     "start_time": "2024-11-05T07:48:37.606147977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div style=\"border-radius: 8px; margin: 10px; padding: 10px; width: Nonepx; background: #e5edf5; border: 0; min-width: 600px;\">\n    <div style=\"display: grid; grid-template-columns: 3fr 1fr; grid-gap: 20px; width:Nonepx;\">\n        <div style=\"padding: 10px 0px 10px 20px;\">\n            \n                <p style=\"font-weight: 600; margin: 0; \">Id: 0</p>\n            \n                <p style=\"font-weight: 600; margin: 0; \">Path: SparkPdf.pdf</p>\n            \n                <p style=\"font-weight: 600; margin: 0; \">Exception: </p>\n            \n        </div>\n        <img src=\"https://deidentify.online/media/filer_public/de/fe/defef052-b877-4052-a9b1-e80cc218fcf4/sparkpdflogo.png\"\n             style=\"width: 150px; margin:20px;justify-self: end;\"/>\n    </div>\n        \n    <div style=\"padding: 0px 0px 0px 20px; font-weight: 600;\">Text:</div>\n    <p><pre style=\"overflow:auto;background-color: white;\">\n\n\n\n\n\n                                        Spark    Pdf\n\n\n\n\n\n\n\n\n\n              Spark Pdf\n\n\n              Spark-Pdf is a library for processing documents using Apache Spark\n              It includes the following features:\n                     Load PDF documents/Images\n                     Extract text from PDF documents/Images\n                     Extract images from PDF documents\n                     OCR Images/PDF documents\n                     Run NER on text extracted from PDF documents/Images\n                     Visualize NER results\n\n              Installation\n\n              Requirements\n                     Python 3.11\n                     Apache Spark 3.5 or higher\n                     Java 8\n                     Tesseract 5.0 or higher\n               pip install spark-pdf</pre></p>\n\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.show_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228fe24595c94aee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Collect recognized text to the local variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2386a2cdfa9884e1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T07:48:37.791587346Z",
     "start_time": "2024-11-05T07:48:37.671766522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        Spark    Pdf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              Spark Pdf\n",
      "\n",
      "\n",
      "              Spark-Pdf is a library for processing documents using Apache Spark\n",
      "              It includes the following features:\n",
      "                     Load PDF documents/Images\n",
      "                     Extract text from PDF documents/Images\n",
      "                     Extract images from PDF documents\n",
      "                     OCR Images/PDF documents\n",
      "                     Run NER on text extracted from PDF documents/Images\n",
      "                     Visualize NER results\n",
      "\n",
      "              Installation\n",
      "\n",
      "              Requirements\n",
      "                     Python 3.11\n",
      "                     Apache Spark 3.5 or higher\n",
      "                     Java 8\n",
      "                     Tesseract 5.0 or higher\n",
      "               pip install spark-pdf\n"
     ]
    }
   ],
   "source": [
    "text = result.select(\"text.text\").collect()[0][0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
